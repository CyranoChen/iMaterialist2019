{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.5.2 (default, Nov 12 2018, 13:43:14) \n",
      "[GCC 5.4.0 20160609] on linux\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy: 1.16.2\n",
      "sklearn: 0.20.3\n",
      "tensorflow 1.13.1\n",
      "keras 2.2.4\n"
     ]
    }
   ],
   "source": [
    "import sys; print('Python %s on %s' % (sys.version, sys.platform))\n",
    "sys.path.extend(['./cnn_finetune'])\n",
    "\n",
    "from load_cifar import load_cifar10_data, load_cifar100_data\n",
    "from keras.utils import multi_gpu_model\n",
    "import numpy as np; print('numpy:', np.__version__)\n",
    "import sklearn; print('sklearn:', sklearn.__version__)\n",
    "import tensorflow as tf; print('tensorflow', tf.__version__)\n",
    "import keras; print('keras', keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow 1.13.1\n",
      "keras 2.2.4\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf; print('tensorflow', tf.__version__)\n",
    "import keras; print('keras', keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from alt_model_checkpoint import AltModelCheckpoint\n",
    "\n",
    "# set gpu visible environment variable\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2\"\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "\n",
    "# cpu\n",
    "# config = tf.ConfigProto(intra_op_parallelism_threads=num_cores, inter_op_parallelism_threads=num_cores, allow_soft_placement=True, device_count={'CPU': 4})\n",
    "    \n",
    "# gpu allow_growth\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "# set memory limit of gpu\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau, TensorBoard, CSVLogger\n",
    "\n",
    "from cnn_finetune.resnet_152 import resnet152_model\n",
    "from cnn_finetune.load_cifar import load_cifar10_data, load_cifar100_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> batch_size: 32\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "load_weights False\n",
      "resnet152_model: classes: 2019 fine-tuning: True\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "data (InputLayer)               (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_zeropadding (ZeroPadding2 (None, 230, 230, 3)  0           data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9408        conv1_zeropadding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "scale_conv1 (Scale)             (None, 112, 112, 64) 128         bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           scale_conv1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 55, 55, 64)   0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 55, 55, 64)   4096        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2a_branch2a (Scale)        (None, 55, 55, 64)   128         bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a_relu (Activation (None, 55, 55, 64)   0           scale2a_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b_zeropadding (Zer (None, 57, 57, 64)   0           res2a_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 55, 55, 64)   36864       res2a_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2a_branch2b (Scale)        (None, 55, 55, 64)   128         bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b_relu (Activation (None, 55, 55, 64)   0           scale2a_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 55, 55, 256)  16384       res2a_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 55, 55, 256)  16384       pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 55, 55, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale2a_branch2c (Scale)        (None, 55, 55, 256)  512         bn2a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale2a_branch1 (Scale)         (None, 55, 55, 256)  512         bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 55, 55, 256)  0           scale2a_branch2c[0][0]           \n",
      "                                                                 scale2a_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res2a_relu (Activation)         (None, 55, 55, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 55, 55, 64)   16384       res2a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2b_branch2a (Scale)        (None, 55, 55, 64)   128         bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a_relu (Activation (None, 55, 55, 64)   0           scale2b_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b_zeropadding (Zer (None, 57, 57, 64)   0           res2b_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 55, 55, 64)   36864       res2b_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2b_branch2b (Scale)        (None, 55, 55, 64)   128         bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b_relu (Activation (None, 55, 55, 64)   0           scale2b_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 55, 55, 256)  16384       res2b_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2b_branch2c (Scale)        (None, 55, 55, 256)  512         bn2b_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b (Add)                     (None, 55, 55, 256)  0           scale2b_branch2c[0][0]           \n",
      "                                                                 res2a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2b_relu (Activation)         (None, 55, 55, 256)  0           res2b[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 55, 55, 64)   16384       res2b_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2c_branch2a (Scale)        (None, 55, 55, 64)   128         bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a_relu (Activation (None, 55, 55, 64)   0           scale2c_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b_zeropadding (Zer (None, 57, 57, 64)   0           res2c_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 55, 55, 64)   36864       res2c_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2c_branch2b (Scale)        (None, 55, 55, 64)   128         bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b_relu (Activation (None, 55, 55, 64)   0           scale2c_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 55, 55, 256)  16384       res2c_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2c_branch2c (Scale)        (None, 55, 55, 256)  512         bn2c_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c (Add)                     (None, 55, 55, 256)  0           scale2c_branch2c[0][0]           \n",
      "                                                                 res2b_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2c_relu (Activation)         (None, 55, 55, 256)  0           res2c[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32768       res2c_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale3a_branch2a (Scale)        (None, 28, 28, 128)  256         bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a_relu (Activation (None, 28, 28, 128)  0           scale3a_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b_zeropadding (Zer (None, 30, 30, 128)  0           res3a_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147456      res3a_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale3a_branch2b (Scale)        (None, 28, 28, 128)  256         bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b_relu (Activation (None, 28, 28, 128)  0           scale3a_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  65536       res3a_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131072      res2c_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale3a_branch2c (Scale)        (None, 28, 28, 512)  1024        bn3a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale3a_branch1 (Scale)         (None, 28, 28, 512)  1024        bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 28, 28, 512)  0           scale3a_branch2c[0][0]           \n",
      "                                                                 scale3a_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res3a_relu (Activation)         (None, 28, 28, 512)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b1_branch2a (Conv2D)        (None, 28, 28, 128)  65536       res3a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn3b1_branch2a (BatchNormalizat (None, 28, 28, 128)  512         res3b1_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b1_branch2a (Scale)       (None, 28, 28, 128)  256         bn3b1_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b1_branch2a_relu (Activatio (None, 28, 28, 128)  0           scale3b1_branch2a[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res3b1_branch2b_zeropadding (Ze (None, 30, 30, 128)  0           res3b1_branch2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "res3b1_branch2b (Conv2D)        (None, 28, 28, 128)  147456      res3b1_branch2b_zeropadding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "bn3b1_branch2b (BatchNormalizat (None, 28, 28, 128)  512         res3b1_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b1_branch2b (Scale)       (None, 28, 28, 128)  256         bn3b1_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b1_branch2b_relu (Activatio (None, 28, 28, 128)  0           scale3b1_branch2b[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res3b1_branch2c (Conv2D)        (None, 28, 28, 512)  65536       res3b1_branch2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn3b1_branch2c (BatchNormalizat (None, 28, 28, 512)  2048        res3b1_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b1_branch2c (Scale)       (None, 28, 28, 512)  1024        bn3b1_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b1 (Add)                    (None, 28, 28, 512)  0           scale3b1_branch2c[0][0]          \n",
      "                                                                 res3a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res3b1_relu (Activation)        (None, 28, 28, 512)  0           res3b1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3b2_branch2a (Conv2D)        (None, 28, 28, 128)  65536       res3b1_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn3b2_branch2a (BatchNormalizat (None, 28, 28, 128)  512         res3b2_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b2_branch2a (Scale)       (None, 28, 28, 128)  256         bn3b2_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b2_branch2a_relu (Activatio (None, 28, 28, 128)  0           scale3b2_branch2a[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res3b2_branch2b_zeropadding (Ze (None, 30, 30, 128)  0           res3b2_branch2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "res3b2_branch2b (Conv2D)        (None, 28, 28, 128)  147456      res3b2_branch2b_zeropadding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "bn3b2_branch2b (BatchNormalizat (None, 28, 28, 128)  512         res3b2_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b2_branch2b (Scale)       (None, 28, 28, 128)  256         bn3b2_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b2_branch2b_relu (Activatio (None, 28, 28, 128)  0           scale3b2_branch2b[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res3b2_branch2c (Conv2D)        (None, 28, 28, 512)  65536       res3b2_branch2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn3b2_branch2c (BatchNormalizat (None, 28, 28, 512)  2048        res3b2_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b2_branch2c (Scale)       (None, 28, 28, 512)  1024        bn3b2_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b2 (Add)                    (None, 28, 28, 512)  0           scale3b2_branch2c[0][0]          \n",
      "                                                                 res3b1_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "res3b2_relu (Activation)        (None, 28, 28, 512)  0           res3b2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3b3_branch2a (Conv2D)        (None, 28, 28, 128)  65536       res3b2_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn3b3_branch2a (BatchNormalizat (None, 28, 28, 128)  512         res3b3_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b3_branch2a (Scale)       (None, 28, 28, 128)  256         bn3b3_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b3_branch2a_relu (Activatio (None, 28, 28, 128)  0           scale3b3_branch2a[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res3b3_branch2b_zeropadding (Ze (None, 30, 30, 128)  0           res3b3_branch2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "res3b3_branch2b (Conv2D)        (None, 28, 28, 128)  147456      res3b3_branch2b_zeropadding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "bn3b3_branch2b (BatchNormalizat (None, 28, 28, 128)  512         res3b3_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b3_branch2b (Scale)       (None, 28, 28, 128)  256         bn3b3_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b3_branch2b_relu (Activatio (None, 28, 28, 128)  0           scale3b3_branch2b[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res3b3_branch2c (Conv2D)        (None, 28, 28, 512)  65536       res3b3_branch2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn3b3_branch2c (BatchNormalizat (None, 28, 28, 512)  2048        res3b3_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b3_branch2c (Scale)       (None, 28, 28, 512)  1024        bn3b3_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b3 (Add)                    (None, 28, 28, 512)  0           scale3b3_branch2c[0][0]          \n",
      "                                                                 res3b2_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "res3b3_relu (Activation)        (None, 28, 28, 512)  0           res3b3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3b4_branch2a (Conv2D)        (None, 28, 28, 128)  65536       res3b3_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn3b4_branch2a (BatchNormalizat (None, 28, 28, 128)  512         res3b4_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b4_branch2a (Scale)       (None, 28, 28, 128)  256         bn3b4_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b4_branch2a_relu (Activatio (None, 28, 28, 128)  0           scale3b4_branch2a[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res3b4_branch2b_zeropadding (Ze (None, 30, 30, 128)  0           res3b4_branch2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "res3b4_branch2b (Conv2D)        (None, 28, 28, 128)  147456      res3b4_branch2b_zeropadding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "bn3b4_branch2b (BatchNormalizat (None, 28, 28, 128)  512         res3b4_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b4_branch2b (Scale)       (None, 28, 28, 128)  256         bn3b4_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b4_branch2b_relu (Activatio (None, 28, 28, 128)  0           scale3b4_branch2b[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res3b4_branch2c (Conv2D)        (None, 28, 28, 512)  65536       res3b4_branch2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn3b4_branch2c (BatchNormalizat (None, 28, 28, 512)  2048        res3b4_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b4_branch2c (Scale)       (None, 28, 28, 512)  1024        bn3b4_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b4 (Add)                    (None, 28, 28, 512)  0           scale3b4_branch2c[0][0]          \n",
      "                                                                 res3b3_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "res3b4_relu (Activation)        (None, 28, 28, 512)  0           res3b4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3b5_branch2a (Conv2D)        (None, 28, 28, 128)  65536       res3b4_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn3b5_branch2a (BatchNormalizat (None, 28, 28, 128)  512         res3b5_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b5_branch2a (Scale)       (None, 28, 28, 128)  256         bn3b5_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b5_branch2a_relu (Activatio (None, 28, 28, 128)  0           scale3b5_branch2a[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res3b5_branch2b_zeropadding (Ze (None, 30, 30, 128)  0           res3b5_branch2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "res3b5_branch2b (Conv2D)        (None, 28, 28, 128)  147456      res3b5_branch2b_zeropadding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "bn3b5_branch2b (BatchNormalizat (None, 28, 28, 128)  512         res3b5_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b5_branch2b (Scale)       (None, 28, 28, 128)  256         bn3b5_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b5_branch2b_relu (Activatio (None, 28, 28, 128)  0           scale3b5_branch2b[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res3b5_branch2c (Conv2D)        (None, 28, 28, 512)  65536       res3b5_branch2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn3b5_branch2c (BatchNormalizat (None, 28, 28, 512)  2048        res3b5_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b5_branch2c (Scale)       (None, 28, 28, 512)  1024        bn3b5_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b5 (Add)                    (None, 28, 28, 512)  0           scale3b5_branch2c[0][0]          \n",
      "                                                                 res3b4_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "res3b5_relu (Activation)        (None, 28, 28, 512)  0           res3b5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3b6_branch2a (Conv2D)        (None, 28, 28, 128)  65536       res3b5_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn3b6_branch2a (BatchNormalizat (None, 28, 28, 128)  512         res3b6_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b6_branch2a (Scale)       (None, 28, 28, 128)  256         bn3b6_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b6_branch2a_relu (Activatio (None, 28, 28, 128)  0           scale3b6_branch2a[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res3b6_branch2b_zeropadding (Ze (None, 30, 30, 128)  0           res3b6_branch2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "res3b6_branch2b (Conv2D)        (None, 28, 28, 128)  147456      res3b6_branch2b_zeropadding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "bn3b6_branch2b (BatchNormalizat (None, 28, 28, 128)  512         res3b6_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b6_branch2b (Scale)       (None, 28, 28, 128)  256         bn3b6_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b6_branch2b_relu (Activatio (None, 28, 28, 128)  0           scale3b6_branch2b[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res3b6_branch2c (Conv2D)        (None, 28, 28, 512)  65536       res3b6_branch2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn3b6_branch2c (BatchNormalizat (None, 28, 28, 512)  2048        res3b6_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b6_branch2c (Scale)       (None, 28, 28, 512)  1024        bn3b6_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b6 (Add)                    (None, 28, 28, 512)  0           scale3b6_branch2c[0][0]          \n",
      "                                                                 res3b5_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "res3b6_relu (Activation)        (None, 28, 28, 512)  0           res3b6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2a (Conv2D)        (None, 28, 28, 128)  65536       res3b6_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn3b7_branch2a (BatchNormalizat (None, 28, 28, 128)  512         res3b7_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b7_branch2a (Scale)       (None, 28, 28, 128)  256         bn3b7_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2a_relu (Activatio (None, 28, 28, 128)  0           scale3b7_branch2a[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2b_zeropadding (Ze (None, 30, 30, 128)  0           res3b7_branch2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2b (Conv2D)        (None, 28, 28, 128)  147456      res3b7_branch2b_zeropadding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "bn3b7_branch2b (BatchNormalizat (None, 28, 28, 128)  512         res3b7_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b7_branch2b (Scale)       (None, 28, 28, 128)  256         bn3b7_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2b_relu (Activatio (None, 28, 28, 128)  0           scale3b7_branch2b[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_branch2c (Conv2D)        (None, 28, 28, 512)  65536       res3b7_branch2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn3b7_branch2c (BatchNormalizat (None, 28, 28, 512)  2048        res3b7_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b7_branch2c (Scale)       (None, 28, 28, 512)  1024        bn3b7_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b7 (Add)                    (None, 28, 28, 512)  0           scale3b7_branch2c[0][0]          \n",
      "                                                                 res3b6_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "res3b7_relu (Activation)        (None, 28, 28, 512)  0           res3b7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131072      res3b7_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale4a_branch2a (Scale)        (None, 14, 14, 256)  512         bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a_relu (Activation (None, 14, 14, 256)  0           scale4a_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b_zeropadding (Zer (None, 16, 16, 256)  0           res4a_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  589824      res4a_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale4a_branch2b (Scale)        (None, 14, 14, 256)  512         bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b_relu (Activation (None, 14, 14, 256)  0           scale4a_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 262144      res4a_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 524288      res3b7_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale4a_branch2c (Scale)        (None, 14, 14, 1024) 2048        bn4a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale4a_branch1 (Scale)         (None, 14, 14, 1024) 2048        bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 14, 14, 1024) 0           scale4a_branch2c[0][0]           \n",
      "                                                                 scale4a_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4a_relu (Activation)         (None, 14, 14, 1024) 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b1_branch2a (Conv2D)        (None, 14, 14, 256)  262144      res4a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn4b1_branch2a (BatchNormalizat (None, 14, 14, 256)  1024        res4b1_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b1_branch2a (Scale)       (None, 14, 14, 256)  512         bn4b1_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b1_branch2a_relu (Activatio (None, 14, 14, 256)  0           scale4b1_branch2a[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res4b1_branch2b_zeropadding (Ze (None, 16, 16, 256)  0           res4b1_branch2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "res4b1_branch2b (Conv2D)        (None, 14, 14, 256)  589824      res4b1_branch2b_zeropadding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "bn4b1_branch2b (BatchNormalizat (None, 14, 14, 256)  1024        res4b1_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b1_branch2b (Scale)       (None, 14, 14, 256)  512         bn4b1_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b1_branch2b_relu (Activatio (None, 14, 14, 256)  0           scale4b1_branch2b[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res4b1_branch2c (Conv2D)        (None, 14, 14, 1024) 262144      res4b1_branch2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn4b1_branch2c (BatchNormalizat (None, 14, 14, 1024) 4096        res4b1_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b1_branch2c (Scale)       (None, 14, 14, 1024) 2048        bn4b1_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b1 (Add)                    (None, 14, 14, 1024) 0           scale4b1_branch2c[0][0]          \n",
      "                                                                 res4a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res4b1_relu (Activation)        (None, 14, 14, 1024) 0           res4b1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b2_branch2a (Conv2D)        (None, 14, 14, 256)  262144      res4b1_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn4b2_branch2a (BatchNormalizat (None, 14, 14, 256)  1024        res4b2_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b2_branch2a (Scale)       (None, 14, 14, 256)  512         bn4b2_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b2_branch2a_relu (Activatio (None, 14, 14, 256)  0           scale4b2_branch2a[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res4b2_branch2b_zeropadding (Ze (None, 16, 16, 256)  0           res4b2_branch2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "res4b2_branch2b (Conv2D)        (None, 14, 14, 256)  589824      res4b2_branch2b_zeropadding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "bn4b2_branch2b (BatchNormalizat (None, 14, 14, 256)  1024        res4b2_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b2_branch2b (Scale)       (None, 14, 14, 256)  512         bn4b2_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b2_branch2b_relu (Activatio (None, 14, 14, 256)  0           scale4b2_branch2b[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res4b2_branch2c (Conv2D)        (None, 14, 14, 1024) 262144      res4b2_branch2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn4b2_branch2c (BatchNormalizat (None, 14, 14, 1024) 4096        res4b2_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b2_branch2c (Scale)       (None, 14, 14, 1024) 2048        bn4b2_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b2 (Add)                    (None, 14, 14, 1024) 0           scale4b2_branch2c[0][0]          \n",
      "                                                                 res4b1_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "res4b2_relu (Activation)        (None, 14, 14, 1024) 0           res4b2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b3_branch2a (Conv2D)        (None, 14, 14, 256)  262144      res4b2_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn4b3_branch2a (BatchNormalizat (None, 14, 14, 256)  1024        res4b3_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b3_branch2a (Scale)       (None, 14, 14, 256)  512         bn4b3_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b3_branch2a_relu (Activatio (None, 14, 14, 256)  0           scale4b3_branch2a[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res4b3_branch2b_zeropadding (Ze (None, 16, 16, 256)  0           res4b3_branch2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "res4b3_branch2b (Conv2D)        (None, 14, 14, 256)  589824      res4b3_branch2b_zeropadding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "bn4b3_branch2b (BatchNormalizat (None, 14, 14, 256)  1024        res4b3_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b3_branch2b (Scale)       (None, 14, 14, 256)  512         bn4b3_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b3_branch2b_relu (Activatio (None, 14, 14, 256)  0           scale4b3_branch2b[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res4b3_branch2c (Conv2D)        (None, 14, 14, 1024) 262144      res4b3_branch2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn4b3_branch2c (BatchNormalizat (None, 14, 14, 1024) 4096        res4b3_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b3_branch2c (Scale)       (None, 14, 14, 1024) 2048        bn4b3_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b3 (Add)                    (None, 14, 14, 1024) 0           scale4b3_branch2c[0][0]          \n",
      "                                                                 res4b2_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "res4b3_relu (Activation)        (None, 14, 14, 1024) 0           res4b3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b4_branch2a (Conv2D)        (None, 14, 14, 256)  262144      res4b3_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn4b4_branch2a (BatchNormalizat (None, 14, 14, 256)  1024        res4b4_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b4_branch2a (Scale)       (None, 14, 14, 256)  512         bn4b4_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b4_branch2a_relu (Activatio (None, 14, 14, 256)  0           scale4b4_branch2a[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res4b4_branch2b_zeropadding (Ze (None, 16, 16, 256)  0           res4b4_branch2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "res4b4_branch2b (Conv2D)        (None, 14, 14, 256)  589824      res4b4_branch2b_zeropadding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "bn4b4_branch2b (BatchNormalizat (None, 14, 14, 256)  1024        res4b4_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b4_branch2b (Scale)       (None, 14, 14, 256)  512         bn4b4_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b4_branch2b_relu (Activatio (None, 14, 14, 256)  0           scale4b4_branch2b[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res4b4_branch2c (Conv2D)        (None, 14, 14, 1024) 262144      res4b4_branch2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn4b4_branch2c (BatchNormalizat (None, 14, 14, 1024) 4096        res4b4_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b4_branch2c (Scale)       (None, 14, 14, 1024) 2048        bn4b4_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b4 (Add)                    (None, 14, 14, 1024) 0           scale4b4_branch2c[0][0]          \n",
      "                                                                 res4b3_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "res4b4_relu (Activation)        (None, 14, 14, 1024) 0           res4b4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b5_branch2a (Conv2D)        (None, 14, 14, 256)  262144      res4b4_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn4b5_branch2a (BatchNormalizat (None, 14, 14, 256)  1024        res4b5_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b5_branch2a (Scale)       (None, 14, 14, 256)  512         bn4b5_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b5_branch2a_relu (Activatio (None, 14, 14, 256)  0           scale4b5_branch2a[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res4b5_branch2b_zeropadding (Ze (None, 16, 16, 256)  0           res4b5_branch2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "res4b5_branch2b (Conv2D)        (None, 14, 14, 256)  589824      res4b5_branch2b_zeropadding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "bn4b5_branch2b (BatchNormalizat (None, 14, 14, 256)  1024        res4b5_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b5_branch2b (Scale)       (None, 14, 14, 256)  512         bn4b5_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b5_branch2b_relu (Activatio (None, 14, 14, 256)  0           scale4b5_branch2b[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res4b5_branch2c (Conv2D)        (None, 14, 14, 1024) 262144      res4b5_branch2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn4b5_branch2c (BatchNormalizat (None, 14, 14, 1024) 4096        res4b5_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b5_branch2c (Scale)       (None, 14, 14, 1024) 2048        bn4b5_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b5 (Add)                    (None, 14, 14, 1024) 0           scale4b5_branch2c[0][0]          \n",
      "                                                                 res4b4_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "res4b5_relu (Activation)        (None, 14, 14, 1024) 0           res4b5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b6_branch2a (Conv2D)        (None, 14, 14, 256)  262144      res4b5_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn4b6_branch2a (BatchNormalizat (None, 14, 14, 256)  1024        res4b6_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b6_branch2a (Scale)       (None, 14, 14, 256)  512         bn4b6_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b6_branch2a_relu (Activatio (None, 14, 14, 256)  0           scale4b6_branch2a[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res4b6_branch2b_zeropadding (Ze (None, 16, 16, 256)  0           res4b6_branch2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "res4b6_branch2b (Conv2D)        (None, 14, 14, 256)  589824      res4b6_branch2b_zeropadding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "bn4b6_branch2b (BatchNormalizat (None, 14, 14, 256)  1024        res4b6_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b6_branch2b (Scale)       (None, 14, 14, 256)  512         bn4b6_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b6_branch2b_relu (Activatio (None, 14, 14, 256)  0           scale4b6_branch2b[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res4b6_branch2c (Conv2D)        (None, 14, 14, 1024) 262144      res4b6_branch2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn4b6_branch2c (BatchNormalizat (None, 14, 14, 1024) 4096        res4b6_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b6_branch2c (Scale)       (None, 14, 14, 1024) 2048        bn4b6_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b6 (Add)                    (None, 14, 14, 1024) 0           scale4b6_branch2c[0][0]          \n",
      "                                                                 res4b5_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "res4b6_relu (Activation)        (None, 14, 14, 1024) 0           res4b6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b7_branch2a (Conv2D)        (None, 14, 14, 256)  262144      res4b6_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn4b7_branch2a (BatchNormalizat (None, 14, 14, 256)  1024        res4b7_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b7_branch2a (Scale)       (None, 14, 14, 256)  512         bn4b7_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b7_branch2a_relu (Activatio (None, 14, 14, 256)  0           scale4b7_branch2a[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res4b7_branch2b_zeropadding (Ze (None, 16, 16, 256)  0           res4b7_branch2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "res4b7_branch2b (Conv2D)        (None, 14, 14, 256)  589824      res4b7_branch2b_zeropadding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "bn4b7_branch2b (BatchNormalizat (None, 14, 14, 256)  1024        res4b7_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b7_branch2b (Scale)       (None, 14, 14, 256)  512         bn4b7_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b7_branch2b_relu (Activatio (None, 14, 14, 256)  0           scale4b7_branch2b[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res4b7_branch2c (Conv2D)        (None, 14, 14, 1024) 262144      res4b7_branch2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn4b7_branch2c (BatchNormalizat (None, 14, 14, 1024) 4096        res4b7_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b7_branch2c (Scale)       (None, 14, 14, 1024) 2048        bn4b7_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b7 (Add)                    (None, 14, 14, 1024) 0           scale4b7_branch2c[0][0]          \n",
      "                                                                 res4b6_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "res4b7_relu (Activation)        (None, 14, 14, 1024) 0           res4b7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b8_branch2a (Conv2D)        (None, 14, 14, 256)  262144      res4b7_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn4b8_branch2a (BatchNormalizat (None, 14, 14, 256)  1024        res4b8_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b8_branch2a (Scale)       (None, 14, 14, 256)  512         bn4b8_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b8_branch2a_relu (Activatio (None, 14, 14, 256)  0           scale4b8_branch2a[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res4b8_branch2b_zeropadding (Ze (None, 16, 16, 256)  0           res4b8_branch2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "res4b8_branch2b (Conv2D)        (None, 14, 14, 256)  589824      res4b8_branch2b_zeropadding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "bn4b8_branch2b (BatchNormalizat (None, 14, 14, 256)  1024        res4b8_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b8_branch2b (Scale)       (None, 14, 14, 256)  512         bn4b8_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b8_branch2b_relu (Activatio (None, 14, 14, 256)  0           scale4b8_branch2b[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res4b8_branch2c (Conv2D)        (None, 14, 14, 1024) 262144      res4b8_branch2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn4b8_branch2c (BatchNormalizat (None, 14, 14, 1024) 4096        res4b8_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b8_branch2c (Scale)       (None, 14, 14, 1024) 2048        bn4b8_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b8 (Add)                    (None, 14, 14, 1024) 0           scale4b8_branch2c[0][0]          \n",
      "                                                                 res4b7_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "res4b8_relu (Activation)        (None, 14, 14, 1024) 0           res4b8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b9_branch2a (Conv2D)        (None, 14, 14, 256)  262144      res4b8_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn4b9_branch2a (BatchNormalizat (None, 14, 14, 256)  1024        res4b9_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b9_branch2a (Scale)       (None, 14, 14, 256)  512         bn4b9_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b9_branch2a_relu (Activatio (None, 14, 14, 256)  0           scale4b9_branch2a[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res4b9_branch2b_zeropadding (Ze (None, 16, 16, 256)  0           res4b9_branch2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "res4b9_branch2b (Conv2D)        (None, 14, 14, 256)  589824      res4b9_branch2b_zeropadding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "bn4b9_branch2b (BatchNormalizat (None, 14, 14, 256)  1024        res4b9_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b9_branch2b (Scale)       (None, 14, 14, 256)  512         bn4b9_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b9_branch2b_relu (Activatio (None, 14, 14, 256)  0           scale4b9_branch2b[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res4b9_branch2c (Conv2D)        (None, 14, 14, 1024) 262144      res4b9_branch2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn4b9_branch2c (BatchNormalizat (None, 14, 14, 1024) 4096        res4b9_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b9_branch2c (Scale)       (None, 14, 14, 1024) 2048        bn4b9_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b9 (Add)                    (None, 14, 14, 1024) 0           scale4b9_branch2c[0][0]          \n",
      "                                                                 res4b8_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "res4b9_relu (Activation)        (None, 14, 14, 1024) 0           res4b9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b10_branch2a (Conv2D)       (None, 14, 14, 256)  262144      res4b9_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn4b10_branch2a (BatchNormaliza (None, 14, 14, 256)  1024        res4b10_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b10_branch2a (Scale)      (None, 14, 14, 256)  512         bn4b10_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b10_branch2a_relu (Activati (None, 14, 14, 256)  0           scale4b10_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b10_branch2b_zeropadding (Z (None, 16, 16, 256)  0           res4b10_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b10_branch2b (Conv2D)       (None, 14, 14, 256)  589824      res4b10_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b10_branch2b (BatchNormaliza (None, 14, 14, 256)  1024        res4b10_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b10_branch2b (Scale)      (None, 14, 14, 256)  512         bn4b10_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b10_branch2b_relu (Activati (None, 14, 14, 256)  0           scale4b10_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b10_branch2c (Conv2D)       (None, 14, 14, 1024) 262144      res4b10_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b10_branch2c (BatchNormaliza (None, 14, 14, 1024) 4096        res4b10_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b10_branch2c (Scale)      (None, 14, 14, 1024) 2048        bn4b10_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b10 (Add)                   (None, 14, 14, 1024) 0           scale4b10_branch2c[0][0]         \n",
      "                                                                 res4b9_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "res4b10_relu (Activation)       (None, 14, 14, 1024) 0           res4b10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4b11_branch2a (Conv2D)       (None, 14, 14, 256)  262144      res4b10_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn4b11_branch2a (BatchNormaliza (None, 14, 14, 256)  1024        res4b11_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b11_branch2a (Scale)      (None, 14, 14, 256)  512         bn4b11_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b11_branch2a_relu (Activati (None, 14, 14, 256)  0           scale4b11_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b11_branch2b_zeropadding (Z (None, 16, 16, 256)  0           res4b11_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b11_branch2b (Conv2D)       (None, 14, 14, 256)  589824      res4b11_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b11_branch2b (BatchNormaliza (None, 14, 14, 256)  1024        res4b11_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b11_branch2b (Scale)      (None, 14, 14, 256)  512         bn4b11_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b11_branch2b_relu (Activati (None, 14, 14, 256)  0           scale4b11_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b11_branch2c (Conv2D)       (None, 14, 14, 1024) 262144      res4b11_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b11_branch2c (BatchNormaliza (None, 14, 14, 1024) 4096        res4b11_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b11_branch2c (Scale)      (None, 14, 14, 1024) 2048        bn4b11_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b11 (Add)                   (None, 14, 14, 1024) 0           scale4b11_branch2c[0][0]         \n",
      "                                                                 res4b10_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4b11_relu (Activation)       (None, 14, 14, 1024) 0           res4b11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4b12_branch2a (Conv2D)       (None, 14, 14, 256)  262144      res4b11_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn4b12_branch2a (BatchNormaliza (None, 14, 14, 256)  1024        res4b12_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b12_branch2a (Scale)      (None, 14, 14, 256)  512         bn4b12_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b12_branch2a_relu (Activati (None, 14, 14, 256)  0           scale4b12_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b12_branch2b_zeropadding (Z (None, 16, 16, 256)  0           res4b12_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b12_branch2b (Conv2D)       (None, 14, 14, 256)  589824      res4b12_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b12_branch2b (BatchNormaliza (None, 14, 14, 256)  1024        res4b12_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b12_branch2b (Scale)      (None, 14, 14, 256)  512         bn4b12_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b12_branch2b_relu (Activati (None, 14, 14, 256)  0           scale4b12_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b12_branch2c (Conv2D)       (None, 14, 14, 1024) 262144      res4b12_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b12_branch2c (BatchNormaliza (None, 14, 14, 1024) 4096        res4b12_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b12_branch2c (Scale)      (None, 14, 14, 1024) 2048        bn4b12_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b12 (Add)                   (None, 14, 14, 1024) 0           scale4b12_branch2c[0][0]         \n",
      "                                                                 res4b11_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4b12_relu (Activation)       (None, 14, 14, 1024) 0           res4b12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4b13_branch2a (Conv2D)       (None, 14, 14, 256)  262144      res4b12_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn4b13_branch2a (BatchNormaliza (None, 14, 14, 256)  1024        res4b13_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b13_branch2a (Scale)      (None, 14, 14, 256)  512         bn4b13_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b13_branch2a_relu (Activati (None, 14, 14, 256)  0           scale4b13_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b13_branch2b_zeropadding (Z (None, 16, 16, 256)  0           res4b13_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b13_branch2b (Conv2D)       (None, 14, 14, 256)  589824      res4b13_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b13_branch2b (BatchNormaliza (None, 14, 14, 256)  1024        res4b13_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b13_branch2b (Scale)      (None, 14, 14, 256)  512         bn4b13_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b13_branch2b_relu (Activati (None, 14, 14, 256)  0           scale4b13_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b13_branch2c (Conv2D)       (None, 14, 14, 1024) 262144      res4b13_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b13_branch2c (BatchNormaliza (None, 14, 14, 1024) 4096        res4b13_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b13_branch2c (Scale)      (None, 14, 14, 1024) 2048        bn4b13_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b13 (Add)                   (None, 14, 14, 1024) 0           scale4b13_branch2c[0][0]         \n",
      "                                                                 res4b12_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4b13_relu (Activation)       (None, 14, 14, 1024) 0           res4b13[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4b14_branch2a (Conv2D)       (None, 14, 14, 256)  262144      res4b13_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn4b14_branch2a (BatchNormaliza (None, 14, 14, 256)  1024        res4b14_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b14_branch2a (Scale)      (None, 14, 14, 256)  512         bn4b14_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b14_branch2a_relu (Activati (None, 14, 14, 256)  0           scale4b14_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b14_branch2b_zeropadding (Z (None, 16, 16, 256)  0           res4b14_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b14_branch2b (Conv2D)       (None, 14, 14, 256)  589824      res4b14_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b14_branch2b (BatchNormaliza (None, 14, 14, 256)  1024        res4b14_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b14_branch2b (Scale)      (None, 14, 14, 256)  512         bn4b14_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b14_branch2b_relu (Activati (None, 14, 14, 256)  0           scale4b14_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b14_branch2c (Conv2D)       (None, 14, 14, 1024) 262144      res4b14_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b14_branch2c (BatchNormaliza (None, 14, 14, 1024) 4096        res4b14_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b14_branch2c (Scale)      (None, 14, 14, 1024) 2048        bn4b14_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b14 (Add)                   (None, 14, 14, 1024) 0           scale4b14_branch2c[0][0]         \n",
      "                                                                 res4b13_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4b14_relu (Activation)       (None, 14, 14, 1024) 0           res4b14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4b15_branch2a (Conv2D)       (None, 14, 14, 256)  262144      res4b14_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn4b15_branch2a (BatchNormaliza (None, 14, 14, 256)  1024        res4b15_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b15_branch2a (Scale)      (None, 14, 14, 256)  512         bn4b15_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b15_branch2a_relu (Activati (None, 14, 14, 256)  0           scale4b15_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b15_branch2b_zeropadding (Z (None, 16, 16, 256)  0           res4b15_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b15_branch2b (Conv2D)       (None, 14, 14, 256)  589824      res4b15_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b15_branch2b (BatchNormaliza (None, 14, 14, 256)  1024        res4b15_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b15_branch2b (Scale)      (None, 14, 14, 256)  512         bn4b15_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b15_branch2b_relu (Activati (None, 14, 14, 256)  0           scale4b15_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b15_branch2c (Conv2D)       (None, 14, 14, 1024) 262144      res4b15_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b15_branch2c (BatchNormaliza (None, 14, 14, 1024) 4096        res4b15_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b15_branch2c (Scale)      (None, 14, 14, 1024) 2048        bn4b15_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b15 (Add)                   (None, 14, 14, 1024) 0           scale4b15_branch2c[0][0]         \n",
      "                                                                 res4b14_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4b15_relu (Activation)       (None, 14, 14, 1024) 0           res4b15[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4b16_branch2a (Conv2D)       (None, 14, 14, 256)  262144      res4b15_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn4b16_branch2a (BatchNormaliza (None, 14, 14, 256)  1024        res4b16_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b16_branch2a (Scale)      (None, 14, 14, 256)  512         bn4b16_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b16_branch2a_relu (Activati (None, 14, 14, 256)  0           scale4b16_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b16_branch2b_zeropadding (Z (None, 16, 16, 256)  0           res4b16_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b16_branch2b (Conv2D)       (None, 14, 14, 256)  589824      res4b16_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b16_branch2b (BatchNormaliza (None, 14, 14, 256)  1024        res4b16_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b16_branch2b (Scale)      (None, 14, 14, 256)  512         bn4b16_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b16_branch2b_relu (Activati (None, 14, 14, 256)  0           scale4b16_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b16_branch2c (Conv2D)       (None, 14, 14, 1024) 262144      res4b16_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b16_branch2c (BatchNormaliza (None, 14, 14, 1024) 4096        res4b16_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b16_branch2c (Scale)      (None, 14, 14, 1024) 2048        bn4b16_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b16 (Add)                   (None, 14, 14, 1024) 0           scale4b16_branch2c[0][0]         \n",
      "                                                                 res4b15_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4b16_relu (Activation)       (None, 14, 14, 1024) 0           res4b16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4b17_branch2a (Conv2D)       (None, 14, 14, 256)  262144      res4b16_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn4b17_branch2a (BatchNormaliza (None, 14, 14, 256)  1024        res4b17_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b17_branch2a (Scale)      (None, 14, 14, 256)  512         bn4b17_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b17_branch2a_relu (Activati (None, 14, 14, 256)  0           scale4b17_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b17_branch2b_zeropadding (Z (None, 16, 16, 256)  0           res4b17_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b17_branch2b (Conv2D)       (None, 14, 14, 256)  589824      res4b17_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b17_branch2b (BatchNormaliza (None, 14, 14, 256)  1024        res4b17_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b17_branch2b (Scale)      (None, 14, 14, 256)  512         bn4b17_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b17_branch2b_relu (Activati (None, 14, 14, 256)  0           scale4b17_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b17_branch2c (Conv2D)       (None, 14, 14, 1024) 262144      res4b17_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b17_branch2c (BatchNormaliza (None, 14, 14, 1024) 4096        res4b17_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b17_branch2c (Scale)      (None, 14, 14, 1024) 2048        bn4b17_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b17 (Add)                   (None, 14, 14, 1024) 0           scale4b17_branch2c[0][0]         \n",
      "                                                                 res4b16_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4b17_relu (Activation)       (None, 14, 14, 1024) 0           res4b17[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4b18_branch2a (Conv2D)       (None, 14, 14, 256)  262144      res4b17_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn4b18_branch2a (BatchNormaliza (None, 14, 14, 256)  1024        res4b18_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b18_branch2a (Scale)      (None, 14, 14, 256)  512         bn4b18_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b18_branch2a_relu (Activati (None, 14, 14, 256)  0           scale4b18_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b18_branch2b_zeropadding (Z (None, 16, 16, 256)  0           res4b18_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b18_branch2b (Conv2D)       (None, 14, 14, 256)  589824      res4b18_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b18_branch2b (BatchNormaliza (None, 14, 14, 256)  1024        res4b18_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b18_branch2b (Scale)      (None, 14, 14, 256)  512         bn4b18_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b18_branch2b_relu (Activati (None, 14, 14, 256)  0           scale4b18_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b18_branch2c (Conv2D)       (None, 14, 14, 1024) 262144      res4b18_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b18_branch2c (BatchNormaliza (None, 14, 14, 1024) 4096        res4b18_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b18_branch2c (Scale)      (None, 14, 14, 1024) 2048        bn4b18_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b18 (Add)                   (None, 14, 14, 1024) 0           scale4b18_branch2c[0][0]         \n",
      "                                                                 res4b17_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4b18_relu (Activation)       (None, 14, 14, 1024) 0           res4b18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4b19_branch2a (Conv2D)       (None, 14, 14, 256)  262144      res4b18_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn4b19_branch2a (BatchNormaliza (None, 14, 14, 256)  1024        res4b19_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b19_branch2a (Scale)      (None, 14, 14, 256)  512         bn4b19_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b19_branch2a_relu (Activati (None, 14, 14, 256)  0           scale4b19_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b19_branch2b_zeropadding (Z (None, 16, 16, 256)  0           res4b19_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b19_branch2b (Conv2D)       (None, 14, 14, 256)  589824      res4b19_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b19_branch2b (BatchNormaliza (None, 14, 14, 256)  1024        res4b19_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b19_branch2b (Scale)      (None, 14, 14, 256)  512         bn4b19_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b19_branch2b_relu (Activati (None, 14, 14, 256)  0           scale4b19_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b19_branch2c (Conv2D)       (None, 14, 14, 1024) 262144      res4b19_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b19_branch2c (BatchNormaliza (None, 14, 14, 1024) 4096        res4b19_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b19_branch2c (Scale)      (None, 14, 14, 1024) 2048        bn4b19_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b19 (Add)                   (None, 14, 14, 1024) 0           scale4b19_branch2c[0][0]         \n",
      "                                                                 res4b18_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4b19_relu (Activation)       (None, 14, 14, 1024) 0           res4b19[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4b20_branch2a (Conv2D)       (None, 14, 14, 256)  262144      res4b19_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn4b20_branch2a (BatchNormaliza (None, 14, 14, 256)  1024        res4b20_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b20_branch2a (Scale)      (None, 14, 14, 256)  512         bn4b20_branch2a[0][0]            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "res4b20_branch2a_relu (Activati (None, 14, 14, 256)  0           scale4b20_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b20_branch2b_zeropadding (Z (None, 16, 16, 256)  0           res4b20_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b20_branch2b (Conv2D)       (None, 14, 14, 256)  589824      res4b20_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b20_branch2b (BatchNormaliza (None, 14, 14, 256)  1024        res4b20_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b20_branch2b (Scale)      (None, 14, 14, 256)  512         bn4b20_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b20_branch2b_relu (Activati (None, 14, 14, 256)  0           scale4b20_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b20_branch2c (Conv2D)       (None, 14, 14, 1024) 262144      res4b20_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b20_branch2c (BatchNormaliza (None, 14, 14, 1024) 4096        res4b20_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b20_branch2c (Scale)      (None, 14, 14, 1024) 2048        bn4b20_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b20 (Add)                   (None, 14, 14, 1024) 0           scale4b20_branch2c[0][0]         \n",
      "                                                                 res4b19_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4b20_relu (Activation)       (None, 14, 14, 1024) 0           res4b20[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4b21_branch2a (Conv2D)       (None, 14, 14, 256)  262144      res4b20_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn4b21_branch2a (BatchNormaliza (None, 14, 14, 256)  1024        res4b21_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b21_branch2a (Scale)      (None, 14, 14, 256)  512         bn4b21_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b21_branch2a_relu (Activati (None, 14, 14, 256)  0           scale4b21_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b21_branch2b_zeropadding (Z (None, 16, 16, 256)  0           res4b21_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b21_branch2b (Conv2D)       (None, 14, 14, 256)  589824      res4b21_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b21_branch2b (BatchNormaliza (None, 14, 14, 256)  1024        res4b21_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b21_branch2b (Scale)      (None, 14, 14, 256)  512         bn4b21_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b21_branch2b_relu (Activati (None, 14, 14, 256)  0           scale4b21_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b21_branch2c (Conv2D)       (None, 14, 14, 1024) 262144      res4b21_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b21_branch2c (BatchNormaliza (None, 14, 14, 1024) 4096        res4b21_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b21_branch2c (Scale)      (None, 14, 14, 1024) 2048        bn4b21_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b21 (Add)                   (None, 14, 14, 1024) 0           scale4b21_branch2c[0][0]         \n",
      "                                                                 res4b20_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4b21_relu (Activation)       (None, 14, 14, 1024) 0           res4b21[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4b22_branch2a (Conv2D)       (None, 14, 14, 256)  262144      res4b21_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn4b22_branch2a (BatchNormaliza (None, 14, 14, 256)  1024        res4b22_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b22_branch2a (Scale)      (None, 14, 14, 256)  512         bn4b22_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b22_branch2a_relu (Activati (None, 14, 14, 256)  0           scale4b22_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b22_branch2b_zeropadding (Z (None, 16, 16, 256)  0           res4b22_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b22_branch2b (Conv2D)       (None, 14, 14, 256)  589824      res4b22_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b22_branch2b (BatchNormaliza (None, 14, 14, 256)  1024        res4b22_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b22_branch2b (Scale)      (None, 14, 14, 256)  512         bn4b22_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b22_branch2b_relu (Activati (None, 14, 14, 256)  0           scale4b22_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b22_branch2c (Conv2D)       (None, 14, 14, 1024) 262144      res4b22_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b22_branch2c (BatchNormaliza (None, 14, 14, 1024) 4096        res4b22_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b22_branch2c (Scale)      (None, 14, 14, 1024) 2048        bn4b22_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b22 (Add)                   (None, 14, 14, 1024) 0           scale4b22_branch2c[0][0]         \n",
      "                                                                 res4b21_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4b22_relu (Activation)       (None, 14, 14, 1024) 0           res4b22[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4b23_branch2a (Conv2D)       (None, 14, 14, 256)  262144      res4b22_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn4b23_branch2a (BatchNormaliza (None, 14, 14, 256)  1024        res4b23_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b23_branch2a (Scale)      (None, 14, 14, 256)  512         bn4b23_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b23_branch2a_relu (Activati (None, 14, 14, 256)  0           scale4b23_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b23_branch2b_zeropadding (Z (None, 16, 16, 256)  0           res4b23_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b23_branch2b (Conv2D)       (None, 14, 14, 256)  589824      res4b23_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b23_branch2b (BatchNormaliza (None, 14, 14, 256)  1024        res4b23_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b23_branch2b (Scale)      (None, 14, 14, 256)  512         bn4b23_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b23_branch2b_relu (Activati (None, 14, 14, 256)  0           scale4b23_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b23_branch2c (Conv2D)       (None, 14, 14, 1024) 262144      res4b23_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b23_branch2c (BatchNormaliza (None, 14, 14, 1024) 4096        res4b23_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b23_branch2c (Scale)      (None, 14, 14, 1024) 2048        bn4b23_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b23 (Add)                   (None, 14, 14, 1024) 0           scale4b23_branch2c[0][0]         \n",
      "                                                                 res4b22_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4b23_relu (Activation)       (None, 14, 14, 1024) 0           res4b23[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4b24_branch2a (Conv2D)       (None, 14, 14, 256)  262144      res4b23_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn4b24_branch2a (BatchNormaliza (None, 14, 14, 256)  1024        res4b24_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b24_branch2a (Scale)      (None, 14, 14, 256)  512         bn4b24_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b24_branch2a_relu (Activati (None, 14, 14, 256)  0           scale4b24_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b24_branch2b_zeropadding (Z (None, 16, 16, 256)  0           res4b24_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b24_branch2b (Conv2D)       (None, 14, 14, 256)  589824      res4b24_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b24_branch2b (BatchNormaliza (None, 14, 14, 256)  1024        res4b24_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b24_branch2b (Scale)      (None, 14, 14, 256)  512         bn4b24_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b24_branch2b_relu (Activati (None, 14, 14, 256)  0           scale4b24_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b24_branch2c (Conv2D)       (None, 14, 14, 1024) 262144      res4b24_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b24_branch2c (BatchNormaliza (None, 14, 14, 1024) 4096        res4b24_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b24_branch2c (Scale)      (None, 14, 14, 1024) 2048        bn4b24_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b24 (Add)                   (None, 14, 14, 1024) 0           scale4b24_branch2c[0][0]         \n",
      "                                                                 res4b23_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4b24_relu (Activation)       (None, 14, 14, 1024) 0           res4b24[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4b25_branch2a (Conv2D)       (None, 14, 14, 256)  262144      res4b24_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn4b25_branch2a (BatchNormaliza (None, 14, 14, 256)  1024        res4b25_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b25_branch2a (Scale)      (None, 14, 14, 256)  512         bn4b25_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b25_branch2a_relu (Activati (None, 14, 14, 256)  0           scale4b25_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b25_branch2b_zeropadding (Z (None, 16, 16, 256)  0           res4b25_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b25_branch2b (Conv2D)       (None, 14, 14, 256)  589824      res4b25_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b25_branch2b (BatchNormaliza (None, 14, 14, 256)  1024        res4b25_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b25_branch2b (Scale)      (None, 14, 14, 256)  512         bn4b25_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b25_branch2b_relu (Activati (None, 14, 14, 256)  0           scale4b25_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b25_branch2c (Conv2D)       (None, 14, 14, 1024) 262144      res4b25_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b25_branch2c (BatchNormaliza (None, 14, 14, 1024) 4096        res4b25_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b25_branch2c (Scale)      (None, 14, 14, 1024) 2048        bn4b25_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b25 (Add)                   (None, 14, 14, 1024) 0           scale4b25_branch2c[0][0]         \n",
      "                                                                 res4b24_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4b25_relu (Activation)       (None, 14, 14, 1024) 0           res4b25[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4b26_branch2a (Conv2D)       (None, 14, 14, 256)  262144      res4b25_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn4b26_branch2a (BatchNormaliza (None, 14, 14, 256)  1024        res4b26_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b26_branch2a (Scale)      (None, 14, 14, 256)  512         bn4b26_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b26_branch2a_relu (Activati (None, 14, 14, 256)  0           scale4b26_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b26_branch2b_zeropadding (Z (None, 16, 16, 256)  0           res4b26_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b26_branch2b (Conv2D)       (None, 14, 14, 256)  589824      res4b26_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b26_branch2b (BatchNormaliza (None, 14, 14, 256)  1024        res4b26_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b26_branch2b (Scale)      (None, 14, 14, 256)  512         bn4b26_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b26_branch2b_relu (Activati (None, 14, 14, 256)  0           scale4b26_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b26_branch2c (Conv2D)       (None, 14, 14, 1024) 262144      res4b26_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b26_branch2c (BatchNormaliza (None, 14, 14, 1024) 4096        res4b26_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b26_branch2c (Scale)      (None, 14, 14, 1024) 2048        bn4b26_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b26 (Add)                   (None, 14, 14, 1024) 0           scale4b26_branch2c[0][0]         \n",
      "                                                                 res4b25_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4b26_relu (Activation)       (None, 14, 14, 1024) 0           res4b26[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4b27_branch2a (Conv2D)       (None, 14, 14, 256)  262144      res4b26_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn4b27_branch2a (BatchNormaliza (None, 14, 14, 256)  1024        res4b27_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b27_branch2a (Scale)      (None, 14, 14, 256)  512         bn4b27_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b27_branch2a_relu (Activati (None, 14, 14, 256)  0           scale4b27_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b27_branch2b_zeropadding (Z (None, 16, 16, 256)  0           res4b27_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b27_branch2b (Conv2D)       (None, 14, 14, 256)  589824      res4b27_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b27_branch2b (BatchNormaliza (None, 14, 14, 256)  1024        res4b27_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b27_branch2b (Scale)      (None, 14, 14, 256)  512         bn4b27_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b27_branch2b_relu (Activati (None, 14, 14, 256)  0           scale4b27_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b27_branch2c (Conv2D)       (None, 14, 14, 1024) 262144      res4b27_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b27_branch2c (BatchNormaliza (None, 14, 14, 1024) 4096        res4b27_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b27_branch2c (Scale)      (None, 14, 14, 1024) 2048        bn4b27_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b27 (Add)                   (None, 14, 14, 1024) 0           scale4b27_branch2c[0][0]         \n",
      "                                                                 res4b26_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4b27_relu (Activation)       (None, 14, 14, 1024) 0           res4b27[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4b28_branch2a (Conv2D)       (None, 14, 14, 256)  262144      res4b27_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn4b28_branch2a (BatchNormaliza (None, 14, 14, 256)  1024        res4b28_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b28_branch2a (Scale)      (None, 14, 14, 256)  512         bn4b28_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b28_branch2a_relu (Activati (None, 14, 14, 256)  0           scale4b28_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b28_branch2b_zeropadding (Z (None, 16, 16, 256)  0           res4b28_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b28_branch2b (Conv2D)       (None, 14, 14, 256)  589824      res4b28_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b28_branch2b (BatchNormaliza (None, 14, 14, 256)  1024        res4b28_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b28_branch2b (Scale)      (None, 14, 14, 256)  512         bn4b28_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b28_branch2b_relu (Activati (None, 14, 14, 256)  0           scale4b28_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b28_branch2c (Conv2D)       (None, 14, 14, 1024) 262144      res4b28_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b28_branch2c (BatchNormaliza (None, 14, 14, 1024) 4096        res4b28_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b28_branch2c (Scale)      (None, 14, 14, 1024) 2048        bn4b28_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b28 (Add)                   (None, 14, 14, 1024) 0           scale4b28_branch2c[0][0]         \n",
      "                                                                 res4b27_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4b28_relu (Activation)       (None, 14, 14, 1024) 0           res4b28[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4b29_branch2a (Conv2D)       (None, 14, 14, 256)  262144      res4b28_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn4b29_branch2a (BatchNormaliza (None, 14, 14, 256)  1024        res4b29_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b29_branch2a (Scale)      (None, 14, 14, 256)  512         bn4b29_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b29_branch2a_relu (Activati (None, 14, 14, 256)  0           scale4b29_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b29_branch2b_zeropadding (Z (None, 16, 16, 256)  0           res4b29_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b29_branch2b (Conv2D)       (None, 14, 14, 256)  589824      res4b29_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b29_branch2b (BatchNormaliza (None, 14, 14, 256)  1024        res4b29_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b29_branch2b (Scale)      (None, 14, 14, 256)  512         bn4b29_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b29_branch2b_relu (Activati (None, 14, 14, 256)  0           scale4b29_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b29_branch2c (Conv2D)       (None, 14, 14, 1024) 262144      res4b29_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b29_branch2c (BatchNormaliza (None, 14, 14, 1024) 4096        res4b29_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b29_branch2c (Scale)      (None, 14, 14, 1024) 2048        bn4b29_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b29 (Add)                   (None, 14, 14, 1024) 0           scale4b29_branch2c[0][0]         \n",
      "                                                                 res4b28_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4b29_relu (Activation)       (None, 14, 14, 1024) 0           res4b29[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4b30_branch2a (Conv2D)       (None, 14, 14, 256)  262144      res4b29_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn4b30_branch2a (BatchNormaliza (None, 14, 14, 256)  1024        res4b30_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b30_branch2a (Scale)      (None, 14, 14, 256)  512         bn4b30_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b30_branch2a_relu (Activati (None, 14, 14, 256)  0           scale4b30_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b30_branch2b_zeropadding (Z (None, 16, 16, 256)  0           res4b30_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b30_branch2b (Conv2D)       (None, 14, 14, 256)  589824      res4b30_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b30_branch2b (BatchNormaliza (None, 14, 14, 256)  1024        res4b30_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b30_branch2b (Scale)      (None, 14, 14, 256)  512         bn4b30_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b30_branch2b_relu (Activati (None, 14, 14, 256)  0           scale4b30_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b30_branch2c (Conv2D)       (None, 14, 14, 1024) 262144      res4b30_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b30_branch2c (BatchNormaliza (None, 14, 14, 1024) 4096        res4b30_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b30_branch2c (Scale)      (None, 14, 14, 1024) 2048        bn4b30_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b30 (Add)                   (None, 14, 14, 1024) 0           scale4b30_branch2c[0][0]         \n",
      "                                                                 res4b29_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4b30_relu (Activation)       (None, 14, 14, 1024) 0           res4b30[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4b31_branch2a (Conv2D)       (None, 14, 14, 256)  262144      res4b30_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn4b31_branch2a (BatchNormaliza (None, 14, 14, 256)  1024        res4b31_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b31_branch2a (Scale)      (None, 14, 14, 256)  512         bn4b31_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b31_branch2a_relu (Activati (None, 14, 14, 256)  0           scale4b31_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b31_branch2b_zeropadding (Z (None, 16, 16, 256)  0           res4b31_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b31_branch2b (Conv2D)       (None, 14, 14, 256)  589824      res4b31_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b31_branch2b (BatchNormaliza (None, 14, 14, 256)  1024        res4b31_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b31_branch2b (Scale)      (None, 14, 14, 256)  512         bn4b31_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b31_branch2b_relu (Activati (None, 14, 14, 256)  0           scale4b31_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b31_branch2c (Conv2D)       (None, 14, 14, 1024) 262144      res4b31_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b31_branch2c (BatchNormaliza (None, 14, 14, 1024) 4096        res4b31_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b31_branch2c (Scale)      (None, 14, 14, 1024) 2048        bn4b31_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b31 (Add)                   (None, 14, 14, 1024) 0           scale4b31_branch2c[0][0]         \n",
      "                                                                 res4b30_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4b31_relu (Activation)       (None, 14, 14, 1024) 0           res4b31[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4b32_branch2a (Conv2D)       (None, 14, 14, 256)  262144      res4b31_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn4b32_branch2a (BatchNormaliza (None, 14, 14, 256)  1024        res4b32_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b32_branch2a (Scale)      (None, 14, 14, 256)  512         bn4b32_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b32_branch2a_relu (Activati (None, 14, 14, 256)  0           scale4b32_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b32_branch2b_zeropadding (Z (None, 16, 16, 256)  0           res4b32_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b32_branch2b (Conv2D)       (None, 14, 14, 256)  589824      res4b32_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b32_branch2b (BatchNormaliza (None, 14, 14, 256)  1024        res4b32_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b32_branch2b (Scale)      (None, 14, 14, 256)  512         bn4b32_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b32_branch2b_relu (Activati (None, 14, 14, 256)  0           scale4b32_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b32_branch2c (Conv2D)       (None, 14, 14, 1024) 262144      res4b32_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b32_branch2c (BatchNormaliza (None, 14, 14, 1024) 4096        res4b32_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b32_branch2c (Scale)      (None, 14, 14, 1024) 2048        bn4b32_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b32 (Add)                   (None, 14, 14, 1024) 0           scale4b32_branch2c[0][0]         \n",
      "                                                                 res4b31_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4b32_relu (Activation)       (None, 14, 14, 1024) 0           res4b32[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4b33_branch2a (Conv2D)       (None, 14, 14, 256)  262144      res4b32_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn4b33_branch2a (BatchNormaliza (None, 14, 14, 256)  1024        res4b33_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b33_branch2a (Scale)      (None, 14, 14, 256)  512         bn4b33_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b33_branch2a_relu (Activati (None, 14, 14, 256)  0           scale4b33_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b33_branch2b_zeropadding (Z (None, 16, 16, 256)  0           res4b33_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b33_branch2b (Conv2D)       (None, 14, 14, 256)  589824      res4b33_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b33_branch2b (BatchNormaliza (None, 14, 14, 256)  1024        res4b33_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b33_branch2b (Scale)      (None, 14, 14, 256)  512         bn4b33_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b33_branch2b_relu (Activati (None, 14, 14, 256)  0           scale4b33_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b33_branch2c (Conv2D)       (None, 14, 14, 1024) 262144      res4b33_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b33_branch2c (BatchNormaliza (None, 14, 14, 1024) 4096        res4b33_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b33_branch2c (Scale)      (None, 14, 14, 1024) 2048        bn4b33_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b33 (Add)                   (None, 14, 14, 1024) 0           scale4b33_branch2c[0][0]         \n",
      "                                                                 res4b32_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4b33_relu (Activation)       (None, 14, 14, 1024) 0           res4b33[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4b34_branch2a (Conv2D)       (None, 14, 14, 256)  262144      res4b33_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn4b34_branch2a (BatchNormaliza (None, 14, 14, 256)  1024        res4b34_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b34_branch2a (Scale)      (None, 14, 14, 256)  512         bn4b34_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b34_branch2a_relu (Activati (None, 14, 14, 256)  0           scale4b34_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b34_branch2b_zeropadding (Z (None, 16, 16, 256)  0           res4b34_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b34_branch2b (Conv2D)       (None, 14, 14, 256)  589824      res4b34_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b34_branch2b (BatchNormaliza (None, 14, 14, 256)  1024        res4b34_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b34_branch2b (Scale)      (None, 14, 14, 256)  512         bn4b34_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b34_branch2b_relu (Activati (None, 14, 14, 256)  0           scale4b34_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b34_branch2c (Conv2D)       (None, 14, 14, 1024) 262144      res4b34_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b34_branch2c (BatchNormaliza (None, 14, 14, 1024) 4096        res4b34_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b34_branch2c (Scale)      (None, 14, 14, 1024) 2048        bn4b34_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b34 (Add)                   (None, 14, 14, 1024) 0           scale4b34_branch2c[0][0]         \n",
      "                                                                 res4b33_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4b34_relu (Activation)       (None, 14, 14, 1024) 0           res4b34[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2a (Conv2D)       (None, 14, 14, 256)  262144      res4b34_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn4b35_branch2a (BatchNormaliza (None, 14, 14, 256)  1024        res4b35_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b35_branch2a (Scale)      (None, 14, 14, 256)  512         bn4b35_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2a_relu (Activati (None, 14, 14, 256)  0           scale4b35_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2b_zeropadding (Z (None, 16, 16, 256)  0           res4b35_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2b (Conv2D)       (None, 14, 14, 256)  589824      res4b35_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b35_branch2b (BatchNormaliza (None, 14, 14, 256)  1024        res4b35_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b35_branch2b (Scale)      (None, 14, 14, 256)  512         bn4b35_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2b_relu (Activati (None, 14, 14, 256)  0           scale4b35_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_branch2c (Conv2D)       (None, 14, 14, 1024) 262144      res4b35_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b35_branch2c (BatchNormaliza (None, 14, 14, 1024) 4096        res4b35_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b35_branch2c (Scale)      (None, 14, 14, 1024) 2048        bn4b35_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b35 (Add)                   (None, 14, 14, 1024) 0           scale4b35_branch2c[0][0]         \n",
      "                                                                 res4b34_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4b35_relu (Activation)       (None, 14, 14, 1024) 0           res4b35[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524288      res4b35_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5a_branch2a (Scale)        (None, 7, 7, 512)    1024        bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a_relu (Activation (None, 7, 7, 512)    0           scale5a_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b_zeropadding (Zer (None, 9, 9, 512)    0           res5a_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359296     res5a_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5a_branch2b (Scale)        (None, 7, 7, 512)    1024        bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b_relu (Activation (None, 7, 7, 512)    0           scale5a_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1048576     res5a_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2097152     res4b35_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale5a_branch2c (Scale)        (None, 7, 7, 2048)   4096        bn5a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale5a_branch1 (Scale)         (None, 7, 7, 2048)   4096        bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 7, 7, 2048)   0           scale5a_branch2c[0][0]           \n",
      "                                                                 scale5a_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res5a_relu (Activation)         (None, 7, 7, 2048)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1048576     res5a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5b_branch2a (Scale)        (None, 7, 7, 512)    1024        bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a_relu (Activation (None, 7, 7, 512)    0           scale5b_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b_zeropadding (Zer (None, 9, 9, 512)    0           res5b_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359296     res5b_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5b_branch2b (Scale)        (None, 7, 7, 512)    1024        bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b_relu (Activation (None, 7, 7, 512)    0           scale5b_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1048576     res5b_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5b_branch2c (Scale)        (None, 7, 7, 2048)   4096        bn5b_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b (Add)                     (None, 7, 7, 2048)   0           scale5b_branch2c[0][0]           \n",
      "                                                                 res5a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res5b_relu (Activation)         (None, 7, 7, 2048)   0           res5b[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1048576     res5b_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5c_branch2a (Scale)        (None, 7, 7, 512)    1024        bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a_relu (Activation (None, 7, 7, 512)    0           scale5c_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b_zeropadding (Zer (None, 9, 9, 512)    0           res5c_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359296     res5c_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5c_branch2b (Scale)        (None, 7, 7, 512)    1024        bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b_relu (Activation (None, 7, 7, 512)    0           scale5c_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1048576     res5c_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5c_branch2c (Scale)        (None, 7, 7, 2048)   4096        bn5c_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c (Add)                     (None, 7, 7, 2048)   0           scale5c_branch2c[0][0]           \n",
      "                                                                 res5b_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res5c_relu (Activation)         (None, 7, 7, 2048)   0           res5c[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           res5c_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2048)         0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fc8 (Dense)                     (None, 2019)         4136931     flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 62,583,587\n",
      "Trainable params: 62,432,163\n",
      "Non-trainable params: 151,424\n",
      "__________________________________________________________________________________________________\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Example to fine-tune on 3000 samples from Cifar10\n",
    "gpus = 2\n",
    "model_name = 'resnet_152_GPU23_e03_2.9979_val_val'\n",
    "dataset_name = 'imaterialist'\n",
    "img_rows, img_cols = 224, 224 # Resolution of inputs\n",
    "channel = 3\n",
    "num_classes = 2019\n",
    "batch_size = 16*gpus\n",
    "print(\">>> batch_size:\", batch_size)\n",
    "epochs = 100\n",
    "load_weights = False\n",
    "fine_tuning = False\n",
    "\n",
    "# Load our model\n",
    "model = resnet152_model(img_rows, img_cols, channel, num_classes, fine_tuning, load_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = '/tf/imaterialist-product-2019/models/resnet_152/imaterialist-e03-2.9979.hd5'\n",
    "model.load_weights(weights_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1008641 images belonging to 2019 classes.\n",
      "Found 10095 images belonging to 2019 classes.\n"
     ]
    }
   ],
   "source": [
    "from lib.DataGenerator import DataGenerator\n",
    "# train_data_generator = DataGenerator(file_type='val', corp=True, batch_size=batch_size)\n",
    "train_data_generator = DataGenerator(file_type='train', corp=True, batch_size=batch_size)\n",
    "val_data_generator = DataGenerator(file_type='val', corp=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = len(train_data_generator)\n",
    "validation_steps = len(val_data_generator)\n",
    "# steps_per_epoch = 10\n",
    "# validation_steps = len(val_data_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31521\n",
      "316\n"
     ]
    }
   ],
   "source": [
    "print(steps_per_epoch)\n",
    "print(validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "data (InputLayer)               (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 224, 224, 3)  0           data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 224, 224, 3)  0           data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, 2019)         62583587    lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fc8 (Concatenate)               (None, 2019)         0           model_2[1][0]                    \n",
      "                                                                 model_2[2][0]                    \n",
      "==================================================================================================\n",
      "Total params: 62,583,587\n",
      "Trainable params: 62,432,163\n",
      "Non-trainable params: 151,424\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks.py:1065: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "# Learning rate is changed to 0.001\n",
    "# adam = Adam(lr=0.1, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, decay=0.0, amsgrad=False)\n",
    "sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "parallel_model = multi_gpu_model(model, gpus=gpus)\n",
    "parallel_model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "parallel_model.summary()\n",
    "checkpoint = AltModelCheckpoint(filepath=\"./models/\" + model_name + \"/\"+ dataset_name +\"-e\" + \"{epoch:02d}-{val_loss:.4f}.hd5\", \n",
    "                             alternate_model = model,\n",
    "                                monitor='val_loss', \n",
    "                             verbose=1, \n",
    "                             save_best_only=False, \n",
    "                             save_weights_only=True, \n",
    "                             mode='auto', \n",
    "                             period=1)\n",
    "\n",
    "checkpoint_best = AltModelCheckpoint(filepath=\"./models/\" + model_name + \"/\"+ dataset_name + \"-best.hd5\", \n",
    "                                  alternate_model = model,\n",
    "                                  monitor='val_loss', \n",
    "                                  verbose=1, \n",
    "                                  save_best_only=True, \n",
    "                                  save_weights_only=True,\n",
    "                                  mode='auto', \n",
    "                                  period=1)\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', \n",
    "                              min_delta=0, \n",
    "                              patience=10, \n",
    "                              verbose=1, \n",
    "                              mode='auto', \n",
    "                              baseline=None, \n",
    "                              restore_best_weights=False)\n",
    "\n",
    "reduceLR = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0)\n",
    "\n",
    "tensorBoard = TensorBoard(log_dir='./models/' + model_name +'/logs', histogram_freq=0, write_graph=True, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n",
    "\n",
    "csvLogger = CSVLogger(filename='./models/'+ model_name + '/' + dataset_name + \"-log.csv\", separator=',', append=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316/316 [==============================] - 120s 380ms/step\n",
      "[2.9978917765463855, 0.35740465579084857]\n"
     ]
    }
   ],
   "source": [
    "valid_evaluate = parallel_model.evaluate_generator(val_data_generator, \n",
    "                                     steps = len(val_data_generator),\n",
    "                                     workers=50, use_multiprocessing=True,\n",
    "                                     verbose=1)\n",
    "print(valid_evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "315/316 [============================>.] - ETA: 1s - loss: 2.5481 - acc: 0.4110Epoch 1/100\n",
      "316/316 [==============================] - 413s 1s/step - loss: 2.5487 - acc: 0.4107 - val_loss: 1.7965 - val_acc: 0.5636\n",
      "\n",
      "Epoch 00001: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e01-1.7965.hd5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.79650, saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-best.hd5\n",
      "Epoch 2/100\n",
      "316/316 [==============================] - 307s 972ms/step - loss: 1.5861 - acc: 0.6002 - val_loss: 1.3685 - val_acc: 0.6606\n",
      "\n",
      "Epoch 00002: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e02-1.3685.hd5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.79650 to 1.36855, saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-best.hd5\n",
      "Epoch 3/100\n",
      "316/316 [==============================] - 287s 910ms/step - loss: 0.9004 - acc: 0.7720 - val_loss: 0.8163 - val_acc: 0.8038\n",
      "\n",
      "Epoch 00003: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e03-0.8163.hd5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.36855 to 0.81630, saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-best.hd5\n",
      "Epoch 4/100\n",
      "316/316 [==============================] - 294s 930ms/step - loss: 0.4022 - acc: 0.9194 - val_loss: 0.3638 - val_acc: 0.9254\n",
      "\n",
      "Epoch 00004: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e04-0.3638.hd5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.81630 to 0.36383, saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-best.hd5\n",
      "Epoch 5/100\n",
      "316/316 [==============================] - 286s 907ms/step - loss: 0.1373 - acc: 0.9871 - val_loss: 0.1773 - val_acc: 0.9721\n",
      "\n",
      "Epoch 00005: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e05-0.1773.hd5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.36383 to 0.17726, saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-best.hd5\n",
      "Epoch 6/100\n",
      "315/316 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9994\n",
      "Epoch 00005: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e05-0.1773.hd5\n",
      "316/316 [==============================] - 285s 903ms/step - loss: 0.0424 - acc: 0.9994 - val_loss: 0.0833 - val_acc: 0.9911\n",
      "\n",
      "Epoch 00006: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e06-0.0833.hd5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.17726 to 0.08329, saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-best.hd5\n",
      "Epoch 7/100\n",
      "316/316 [==============================] - 284s 899ms/step - loss: 0.0196 - acc: 0.9996 - val_loss: 0.0575 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00007: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e07-0.0575.hd5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.08329 to 0.05754, saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-best.hd5\n",
      "Epoch 8/100\n",
      "316/316 [==============================] - 290s 918ms/step - loss: 0.0120 - acc: 0.9997 - val_loss: 0.0409 - val_acc: 0.9947\n",
      "\n",
      "Epoch 00008: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e08-0.0409.hd5\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.05754 to 0.04092, saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-best.hd5\n",
      "Epoch 9/100\n",
      "316/316 [==============================] - 287s 909ms/step - loss: 0.0082 - acc: 0.9997 - val_loss: 0.0293 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00009: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e09-0.0293.hd5\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.04092 to 0.02930, saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-best.hd5\n",
      "Epoch 10/100\n",
      "316/316 [==============================] - 294s 930ms/step - loss: 0.0062 - acc: 0.9997 - val_loss: 0.0203 - val_acc: 0.9974\n",
      "\n",
      "Epoch 00010: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e10-0.0203.hd5\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.02930 to 0.02025, saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-best.hd5\n",
      "Epoch 11/100\n",
      "316/316 [==============================] - 286s 905ms/step - loss: 0.0053 - acc: 0.9997 - val_loss: 0.0153 - val_acc: 0.9977\n",
      "\n",
      "Epoch 00011: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e11-0.0153.hd5\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.02025 to 0.01532, saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-best.hd5\n",
      "Epoch 12/100\n",
      "316/316 [==============================] - 289s 916ms/step - loss: 0.0050 - acc: 0.9997 - val_loss: 0.0122 - val_acc: 0.9983\n",
      "\n",
      "Epoch 00012: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e12-0.0122.hd5\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01532 to 0.01218, saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-best.hd5\n",
      "Epoch 13/100\n",
      "316/316 [==============================] - 289s 916ms/step - loss: 0.0049 - acc: 0.9997 - val_loss: 0.0103 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00013: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e13-0.0103.hd5\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01218 to 0.01032, saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-best.hd5\n",
      "Epoch 14/100\n",
      "316/316 [==============================] - 282s 893ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0088 - val_acc: 0.9989\n",
      "\n",
      "Epoch 00014: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e14-0.0088.hd5\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.01032 to 0.00880, saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-best.hd5\n",
      "Epoch 15/100\n",
      "315/316 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9997\n",
      "Epoch 00014: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e14-0.0088.hd5\n",
      "316/316 [==============================] - 290s 917ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00015: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e15-0.0082.hd5\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00880 to 0.00819, saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-best.hd5\n",
      "Epoch 16/100\n",
      "316/316 [==============================] - 288s 912ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0081 - val_acc: 0.9989\n",
      "\n",
      "Epoch 00016: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e16-0.0081.hd5\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00819 to 0.00810, saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-best.hd5\n",
      "Epoch 17/100\n",
      "316/316 [==============================] - 286s 906ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0076 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00017: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e17-0.0076.hd5\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00810 to 0.00758, saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-best.hd5\n",
      "Epoch 18/100\n",
      "315/316 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9997\n",
      "316/316 [==============================] - 287s 908ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0072 - val_acc: 0.9993\n",
      "\n",
      "Epoch 00018: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e18-0.0072.hd5\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00758 to 0.00723, saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-best.hd5\n",
      "Epoch 19/100\n",
      "316/316 [==============================] - 286s 904ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0071 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00019: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e19-0.0071.hd5\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00723 to 0.00712, saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-best.hd5\n",
      "Epoch 20/100\n",
      "316/316 [==============================] - 285s 901ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0067 - val_acc: 0.9993\n",
      "\n",
      "Epoch 00020: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e20-0.0067.hd5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00020: val_loss improved from 0.00712 to 0.00672, saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-best.hd5\n",
      "Epoch 21/100\n",
      "316/316 [==============================] - 286s 904ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0070 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00021: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e21-0.0070.hd5\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00672\n",
      "Epoch 22/100\n",
      "315/316 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9997\n",
      "Epoch 00021: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e21-0.0070.hd5\n",
      "316/316 [==============================] - 287s 908ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0068 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00022: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e22-0.0068.hd5\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.00672\n",
      "Epoch 23/100\n",
      "316/316 [==============================] - 281s 890ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0067 - val_acc: 0.9993\n",
      "\n",
      "Epoch 00023: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e23-0.0067.hd5\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.00672 to 0.00668, saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-best.hd5\n",
      "Epoch 24/100\n",
      "316/316 [==============================] - 285s 903ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0065 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00024: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e24-0.0065.hd5\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00668 to 0.00655, saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-best.hd5\n",
      "Epoch 25/100\n",
      "315/316 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9997\n",
      "Epoch 00024: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e24-0.0065.hd5\n",
      "316/316 [==============================] - 289s 915ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0066 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00025: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e25-0.0066.hd5\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00655\n",
      "Epoch 26/100\n",
      "316/316 [==============================] - 281s 890ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0065 - val_acc: 0.9993\n",
      "\n",
      "Epoch 00026: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e26-0.0065.hd5\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00655 to 0.00651, saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-best.hd5\n",
      "Epoch 27/100\n",
      "316/316 [==============================] - 286s 904ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0066 - val_acc: 0.9993\n",
      "\n",
      "Epoch 00027: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e27-0.0066.hd5\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.00651\n",
      "Epoch 28/100\n",
      "316/316 [==============================] - 284s 899ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0065 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00028: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e28-0.0065.hd5\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00651 to 0.00650, saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-best.hd5\n",
      "Epoch 29/100\n",
      "315/316 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9997\n",
      "Epoch 00028: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e28-0.0065.hd5\n",
      "316/316 [==============================] - 287s 907ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0065 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00029: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e29-0.0065.hd5\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00650 to 0.00648, saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-best.hd5\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 30/100\n",
      "316/316 [==============================] - 299s 948ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0065 - val_acc: 0.9994\n",
      "\n",
      "Epoch 00030: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e30-0.0065.hd5\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00648\n",
      "Epoch 31/100\n",
      "316/316 [==============================] - 284s 898ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0066 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00031: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e31-0.0066.hd5\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00648\n",
      "Epoch 32/100\n",
      "316/316 [==============================] - 286s 905ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0067 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00032: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e32-0.0067.hd5\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00648\n",
      "Epoch 33/100\n",
      "316/316 [==============================] - 286s 906ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0066 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00033: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e33-0.0066.hd5\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.00648\n",
      "Epoch 34/100\n",
      "316/316 [==============================] - 284s 898ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0065 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00034: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e34-0.0065.hd5\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00648 to 0.00647, saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-best.hd5\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 35/100\n",
      "316/316 [==============================] - 286s 904ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0064 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00035: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e35-0.0064.hd5\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00647 to 0.00642, saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-best.hd5\n",
      "Epoch 36/100\n",
      "316/316 [==============================] - 287s 909ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0066 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00036: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e36-0.0066.hd5\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.00642\n",
      "Epoch 37/100\n",
      "316/316 [==============================] - 288s 912ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0065 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00037: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e37-0.0065.hd5\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.00642\n",
      "Epoch 38/100\n",
      "316/316 [==============================] - 288s 913ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0064 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00038: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e38-0.0064.hd5\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00642 to 0.00641, saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-best.hd5\n",
      "Epoch 39/100\n",
      "316/316 [==============================] - 289s 914ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0064 - val_acc: 0.9994\n",
      "\n",
      "Epoch 00039: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e39-0.0064.hd5\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00641 to 0.00639, saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-best.hd5\n",
      "Epoch 40/100\n",
      "316/316 [==============================] - 286s 907ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0065 - val_acc: 0.9994\n",
      "\n",
      "Epoch 00040: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e40-0.0065.hd5\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00639\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 41/100\n",
      "316/316 [==============================] - 284s 899ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0065 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00041: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e41-0.0065.hd5\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.00639\n",
      "Epoch 42/100\n",
      "316/316 [==============================] - 286s 904ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0065 - val_acc: 0.9994\n",
      "\n",
      "Epoch 00042: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e42-0.0065.hd5\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.00639\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315/316 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9997\n",
      "316/316 [==============================] - 284s 899ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0065 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00043: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e43-0.0065.hd5\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.00639\n",
      "Epoch 44/100\n",
      "316/316 [==============================] - 282s 894ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0064 - val_acc: 0.9994\n",
      "\n",
      "Epoch 00044: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e44-0.0064.hd5\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.00639\n",
      "Epoch 45/100\n",
      "316/316 [==============================] - 285s 902ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0064 - val_acc: 0.9993\n",
      "\n",
      "Epoch 00045: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e45-0.0064.hd5\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00639 to 0.00635, saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-best.hd5\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 46/100\n",
      "316/316 [==============================] - 283s 894ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0065 - val_acc: 0.9993\n",
      "\n",
      "Epoch 00046: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e46-0.0065.hd5\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.00635\n",
      "Epoch 47/100\n",
      "316/316 [==============================] - 286s 905ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0065 - val_acc: 0.9993\n",
      "\n",
      "Epoch 00047: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e47-0.0065.hd5\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.00635\n",
      "Epoch 48/100\n",
      "316/316 [==============================] - 285s 903ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0065 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00048: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e48-0.0065.hd5\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.00635\n",
      "Epoch 49/100\n",
      "316/316 [==============================] - 283s 895ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0065 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00049: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e49-0.0065.hd5\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.00635\n",
      "Epoch 50/100\n",
      "316/316 [==============================] - 289s 913ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0065 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00050: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e50-0.0065.hd5\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.00635\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 51/100\n",
      "316/316 [==============================] - 285s 903ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0066 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00051: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e51-0.0066.hd5\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.00635\n",
      "Epoch 52/100\n",
      "316/316 [==============================] - 288s 910ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0066 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00052: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e52-0.0066.hd5\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.00635\n",
      "Epoch 53/100\n",
      "316/316 [==============================] - 288s 910ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0065 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00053: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e53-0.0065.hd5\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.00635\n",
      "Epoch 54/100\n",
      "316/316 [==============================] - 288s 912ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0065 - val_acc: 0.9993\n",
      "\n",
      "Epoch 00054: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e54-0.0065.hd5\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.00635\n",
      "Epoch 55/100\n",
      "316/316 [==============================] - 284s 898ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0065 - val_acc: 0.9993\n",
      "\n",
      "Epoch 00055: saving model to ./models/resnet_152_GPU23_e03_2.9979_val_val/imaterialist-e55-0.0065.hd5\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.00635\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 00055: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f58cf0795c0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_model.fit_generator(val_data_generator,\n",
    "          steps_per_epoch = validation_steps,\n",
    "          epochs=epochs,\n",
    "          shuffle=True,\n",
    "          verbose=1,\n",
    "          validation_data=val_data_generator,\n",
    "          validation_steps=validation_steps,\n",
    "          workers=50,\n",
    "          use_multiprocessing=True,\n",
    "          callbacks=[checkpoint, checkpoint_best, reduceLR, earlyStopping, tensorBoard, csvLogger]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31521/31521 [==============================] - 11049s 351ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7.772719023425045, 0.30607718702690057]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_model.evaluate_generator(train_data_generator, \n",
    "                                     steps = len(train_data_generator),\n",
    "                                     workers=50, use_multiprocessing=True,\n",
    "                                     verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "31521/31521 [==============================] - 21167s 672ms/step - loss: 3.2952 - acc: 0.3982 - val_loss: 7.7043 - val_acc: 4.9529e-04\n",
      "\n",
      "Epoch 00001: saving model to ./models/resnet_152_GPU23_e03_2.9979/imaterialist-e01-7.7043.hd5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-249:\n",
      "Process ForkPoolWorker-237:\n",
      "Process ForkPoolWorker-201:\n",
      "Process ForkPoolWorker-206:\n",
      "Process ForkPoolWorker-218:\n",
      "Process ForkPoolWorker-266:\n",
      "Process ForkPoolWorker-244:\n",
      "Process ForkPoolWorker-246:\n",
      "Process ForkPoolWorker-216:\n",
      "Process ForkPoolWorker-202:\n",
      "Process ForkPoolWorker-287:\n",
      "Process ForkPoolWorker-298:\n",
      "Process ForkPoolWorker-219:\n",
      "Process ForkPoolWorker-242:\n",
      "Process ForkPoolWorker-209:\n",
      "Process ForkPoolWorker-296:\n",
      "Process ForkPoolWorker-259:\n",
      "Process ForkPoolWorker-286:\n",
      "Process ForkPoolWorker-272:\n",
      "Process ForkPoolWorker-257:\n",
      "Process ForkPoolWorker-215:\n",
      "Process ForkPoolWorker-230:\n",
      "Process ForkPoolWorker-282:\n",
      "Process ForkPoolWorker-261:\n",
      "Process ForkPoolWorker-294:\n",
      "Process ForkPoolWorker-243:\n",
      "Process ForkPoolWorker-275:\n",
      "Process ForkPoolWorker-270:\n",
      "Process ForkPoolWorker-262:\n",
      "Process ForkPoolWorker-205:\n",
      "Process ForkPoolWorker-273:\n",
      "Process ForkPoolWorker-293:\n",
      "Process ForkPoolWorker-263:\n",
      "Process ForkPoolWorker-217:\n",
      "Process ForkPoolWorker-220:\n",
      "Process ForkPoolWorker-265:\n",
      "Process ForkPoolWorker-288:\n",
      "Process ForkPoolWorker-255:\n",
      "Process ForkPoolWorker-221:\n",
      "Process ForkPoolWorker-297:\n",
      "Process ForkPoolWorker-291:\n",
      "Process ForkPoolWorker-292:\n",
      "Process ForkPoolWorker-238:\n",
      "Process ForkPoolWorker-241:\n",
      "Process ForkPoolWorker-281:\n",
      "Process ForkPoolWorker-245:\n",
      "Process ForkPoolWorker-251:\n",
      "Process ForkPoolWorker-222:\n",
      "Process ForkPoolWorker-260:\n",
      "Process ForkPoolWorker-250:\n",
      "Process ForkPoolWorker-256:\n",
      "Process ForkPoolWorker-247:\n",
      "Process ForkPoolWorker-253:\n",
      "Process ForkPoolWorker-203:\n",
      "Process ForkPoolWorker-248:\n",
      "Process ForkPoolWorker-271:\n",
      "Process ForkPoolWorker-235:\n",
      "Process ForkPoolWorker-208:\n",
      "Process ForkPoolWorker-267:\n",
      "Process ForkPoolWorker-252:\n",
      "Process ForkPoolWorker-278:\n",
      "Process ForkPoolWorker-268:\n",
      "Process ForkPoolWorker-285:\n",
      "Process ForkPoolWorker-277:\n",
      "Process ForkPoolWorker-269:\n",
      "Process ForkPoolWorker-211:\n",
      "Process ForkPoolWorker-290:\n",
      "Process ForkPoolWorker-231:\n",
      "Process ForkPoolWorker-283:\n",
      "Process ForkPoolWorker-276:\n",
      "Process ForkPoolWorker-299:\n",
      "Process ForkPoolWorker-279:\n",
      "Process ForkPoolWorker-233:\n",
      "Process ForkPoolWorker-207:\n",
      "Process ForkPoolWorker-295:\n",
      "Process ForkPoolWorker-212:\n",
      "Process ForkPoolWorker-240:\n",
      "Process ForkPoolWorker-274:\n",
      "Process ForkPoolWorker-264:\n",
      "Process ForkPoolWorker-214:\n",
      "Process ForkPoolWorker-213:\n",
      "Process ForkPoolWorker-234:\n",
      "Process ForkPoolWorker-280:\n",
      "Process ForkPoolWorker-239:\n",
      "Process ForkPoolWorker-229:\n",
      "Process ForkPoolWorker-232:\n",
      "Process ForkPoolWorker-300:\n",
      "Process ForkPoolWorker-284:\n",
      "Process ForkPoolWorker-289:\n",
      "Process ForkPoolWorker-236:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-210:\n",
      "Process ForkPoolWorker-254:\n",
      "Process ForkPoolWorker-258:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-204:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-225:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-226:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-224:\n",
      "Process ForkPoolWorker-223:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-228:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-227:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ff62aa5e4ce8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m           \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_best\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduceLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearlyStopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensorBoard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsvLogger\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m           )\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    249\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m             \u001b[0mepoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/alt_model_checkpoint/__init__.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mmodel_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malternate_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_before\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    453\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nEpoch %05d: saving model to %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36msave_weights\u001b[0;34m(self, filepath, overwrite)\u001b[0m\n\u001b[1;32m   1119\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m             \u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights_to_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36msave_weights_to_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0msymbolic_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mweight_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m         \u001b[0mweight_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_get_value\u001b[0;34m(ops)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \"\"\"\n\u001b[1;32m   2419\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "parallel_model.fit_generator(train_data_generator,\n",
    "          steps_per_epoch = steps_per_epoch,\n",
    "          epochs=epochs,\n",
    "          shuffle=True,\n",
    "          verbose=1,\n",
    "          validation_data=val_data_generator,\n",
    "          validation_steps=validation_steps,\n",
    "          workers=50,\n",
    "          use_multiprocessing=True,\n",
    "          callbacks=[checkpoint, checkpoint_best, reduceLR, earlyStopping, tensorBoard, csvLogger]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "# predictions_valid = model.predict(X_valid, batch_size=batch_size, verbose=1)\n",
    "# print(Y_valid.shape, predictions_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# np.set_printoptions(threshold=np.inf)\n",
    "# print(Y_valid)\n",
    "# print(predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('cross-entropy:', sklearn.metrics.log_loss(Y_valid, predictions_valid))\n",
    "\n",
    "# y_true = np.argmax(Y_valid, axis=1)\n",
    "# y_hat = np.argmax(predictions_valid, axis=1)\n",
    "# # print('report:', sklearn.metrics.classification_report(y_true, y_hat))\n",
    "# print('acc:', sklearn.metrics.accuracy_score(y_true, y_hat))\n",
    "# # print('roc:', sklearn.metrics.roc_auc_score(y_true, y_hat))\n",
    "# # print('confusion_matrix:\\n', sklearn.metrics.confusion_matrix(y_true, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
